"""Node functions for LangGraph agent pipeline"""
from typing import TypedDict, List, Dict, Any, Annotated
import uuid
from datetime import datetime
from collections import defaultdict
import polars as pl
from src.db.clickhouse_client import get_clickhouse_client
from src.db.session import get_db_context
from src.db.models import Source
from src.services.hotness_scorer import get_hotness_scorer
from src.services.ml_scorer import get_ml_scorer
from src.services.llm_client import get_llm_client
from src.core.logging_config import log


class AgentState(TypedDict):
    """State object passed between nodes in the graph"""
    time_window_hours: int
    top_k: int
    raw_articles: List[Dict[str, Any]]
    clustered_articles: Dict[str, List[Dict[str, Any]]]
    scored_clusters: List[Dict[str, Any]]
    enriched_results: List[Dict[str, Any]]
    final_output: List[Dict[str, Any]]


def fetch_recent_news_node(state: AgentState) -> AgentState:
    """Node 1: Fetch recent news from ClickHouse"""
    log.info(f"Fetching news from last {state['time_window_hours']} hours")
    
    clickhouse = get_clickhouse_client()
    articles = clickhouse.get_recent_articles(state["time_window_hours"])
    
    state["raw_articles"] = articles
    log.info(f"Fetched {len(articles)} articles")
    
    return state


def cluster_articles_node(state: AgentState) -> AgentState:
    """Node 2: Group articles by dedup_group"""
    log.info("Clustering articles by dedup_group")
    
    clusters = defaultdict(list)
    for article in state["raw_articles"]:
        dedup_group = article.get("dedup_group")
        if dedup_group:
            clusters[str(dedup_group)].append(article)
    
    state["clustered_articles"] = dict(clusters)
    log.info(f"Created {len(clusters)} clusters")
    
    return state


def calculate_hotness_node(state: AgentState) -> AgentState:
    """Node 3: Calculate hotness score for each cluster"""
    log.info("Calculating hotness scores")

    scorer = get_hotness_scorer()
    scored_clusters = []

    # Fetch source reputation scores
    with get_db_context() as db:
        sources = {s.id: s.reputation_score for s in db.query(Source).all()}

    for dedup_group, articles in state["clustered_articles"].items():
        # Get reputation scores for articles in this cluster
        reputation_scores = [
            sources.get(article.get("source_id"), 0.5)
            for article in articles
        ]

        hotness = scorer.calculate_hotness(
            articles=articles,
            source_reputation_scores=reputation_scores,
            time_window_hours=state["time_window_hours"],
        )

        scored_clusters.append({
            "dedup_group": dedup_group,
            "articles": articles,
            "hotness": hotness,
            "article_count": len(articles),
        })

    # Sort by hotness score (descending)
    scored_clusters.sort(key=lambda x: x["hotness"], reverse=True)

    state["scored_clusters"] = scored_clusters
    log.info(f"Scored {len(scored_clusters)} clusters")

    return state


def calculate_ml_hotness_node(state: AgentState) -> AgentState:
    """Node 3.5: Calculate ML-based hotness scores for clusters"""
    log.info("Calculating ML-based hotness scores")

    ml_scorer = get_ml_scorer()
    ml_scored_clusters = []

    for cluster in state["scored_clusters"]:
        dedup_group = cluster["dedup_group"]
        articles = cluster["articles"]

        # Get ML scores for all articles in this cluster
        ml_scored_articles = ml_scorer.score_articles(articles)

        # Calculate average ML score for the cluster
        ml_scores = [article.get("ml_hot_score", 0.0) for article in ml_scored_articles]
        avg_ml_score = sum(ml_scores) / len(ml_scores) if ml_scores else 0.0

        # Update cluster with ML score
        cluster_copy = cluster.copy()
        cluster_copy["ml_hotness"] = avg_ml_score
        cluster_copy["ml_scored_articles"] = ml_scored_articles

        ml_scored_clusters.append(cluster_copy)

    state["ml_scored_clusters"] = ml_scored_clusters
    log.info(f"Calculated ML scores for {len(ml_scored_clusters)} clusters")

    return state


def rank_and_select_node(state: AgentState) -> AgentState:
    """Node 4: Select top K clusters using combined scoring"""
    log.info(f"Selecting top {state['top_k']} clusters using combined scoring")

    # Get clusters with both traditional and ML scores
    clusters = state.get("ml_scored_clusters", state.get("scored_clusters", []))

    if not clusters:
        log.warning("No clusters available for ranking")
        state["enriched_results"] = []
        return state

    # Calculate combined scores for ranking
    for cluster in clusters:
        traditional_score = cluster.get("hotness", 0.0)
        ml_score = cluster.get("ml_hotness", 0.0)

        # Weighted combination (70% traditional, 30% ML for conservative approach)
        combined_score = (traditional_score * 0.7) + (ml_score * 0.3)
        cluster["combined_hotness"] = combined_score

        log.debug(f"Cluster {cluster['dedup_group'][:8]}: "
                 f"Traditional={traditional_score:.3f}, ML={ml_score:.3f}, "
                 f"Combined={combined_score:.3f}")

    # Sort by combined score (descending)
    clusters.sort(key=lambda x: x.get("combined_hotness", 0.0), reverse=True)

    # Select top K clusters
    top_clusters = clusters[: state["top_k"]]
    state["enriched_results"] = top_clusters

    log.info(f"Selected {len(top_clusters)} clusters for enrichment")
    log.info(f"Top cluster combined scores: {[(c['dedup_group'][:8], c.get('combined_hotness', 0.0)) for c in top_clusters]}")

    return state


def enrich_with_llm_node(state: AgentState) -> AgentState:
    """Node 5: Enrich top clusters with LLM-generated content"""
    log.info("Enriching clusters with LLM")
    
    llm = get_llm_client()
    final_results = []
    
    for cluster in state["enriched_results"]:
        articles = cluster["articles"]
        
        # Consolidate article content
        consolidated_text = "\n\n---\n\n".join([
            f"Title: {art.get('title', '')}\n"
            f"Source ID: {art.get('source_id', '')}\n"
            f"Published: {art.get('published_at', '')}\n"
            f"URL: {art.get('url', '')}\n"
            f"Content: {art.get('content', '')[:1000]}"  # Limit content length
            for art in articles
        ])
        
        # Generate enriched data with LLM
        try:
            prompt = f"""–¢—ã ‚Äî —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –Ω–æ–≤–æ—Å—Ç–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –∏ —Å–æ–∑–¥–∞—Ç–µ–ª—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è Telegram. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–µ –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç.

–ù–æ–≤–æ—Å—Ç–Ω—ã–µ —Å—Ç–∞—Ç—å–∏:
{consolidated_text}

–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π JSON –æ—Ç–≤–µ—Ç —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –ø–æ–ª—è–º–∏:

1. "headline": –ö—Ä–∞—Ç–∫–∏–π, —è—Ä–∫–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–º–∞–∫—Å–∏–º—É–º 100 —Å–∏–º–≤–æ–ª–æ–≤)

2. "why_now": 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –æ–±—ä—è—Å–Ω—è—é—â–∏–µ, –ø–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ –°–ï–ô–ß–ê–° (–Ω–æ–≤–∏–∑–Ω–∞, –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è, –º–∞—Å—à—Ç–∞–± –≤–ª–∏—è–Ω–∏—è)

3. "entities": –°–ø–∏—Å–æ–∫ –∫–æ–º–ø–∞–Ω–∏–π, —Ç–∏–∫–µ—Ä–æ–≤, —Å—Ç—Ä–∞–Ω –∏–ª–∏ —Å–µ–∫—Ç–æ—Ä–æ–≤, —É–ø–æ–º—è–Ω—É—Ç—ã—Ö –≤ –Ω–æ–≤–æ—Å—Ç—è—Ö (–º–∞–∫—Å–∏–º—É–º 10 —ç–ª–µ–º–µ–Ω—Ç–æ–≤)

4. "timeline": –°–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ç–æ—á–µ–∫ —Å –∫—Ä–∞—Ç–∫–∏–º–∏ –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ (—Ñ–æ—Ä–º–∞—Ç: [{{"time": "YYYY-MM-DD HH:MM", "event": "–æ–ø–∏—Å–∞–Ω–∏–µ"}}])

5. "draft": –ü–æ–ª–Ω—ã–π —á–µ—Ä–Ω–æ–≤–∏–∫ –ø–æ—Å—Ç–∞ –∫–∞–∫ –û–î–ù–ê –°–¢–†–û–ö–ê —Å markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º. –í–∫–ª—é—á–∏:
   - –í–≤–æ–¥–Ω—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
   - 3 –∫–ª—é—á–µ–≤—ã—Ö –ø—É–Ω–∫—Ç–∞ (–∏—Å–ø–æ–ª—å–∑—É–π - –¥–ª—è –±—É–ª–ª–∏—Ç–æ–≤)
   - –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é —Ü–∏—Ç–∞—Ç—É –∏–ª–∏ —Å—Å—ã–ª–∫—É —Å –∞—Ç—Ä–∏–±—É—Ü–∏–µ–π

6. "telegram_post": –ì–æ—Ç–æ–≤—ã–π –∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –ø–æ—Å—Ç –¥–ª—è Telegram –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ñ–æ—Ä–º–∞—Ç–µ:
   - –ù–∞—á–Ω–∏ —Å –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ —ç–º–æ–¥–∑–∏ (‚ö°Ô∏è –¥–ª—è —Å—Ä–æ—á–Ω–æ–≥–æ/–≤–∞–∂–Ω–æ–≥–æ, üòÄ –¥–ª—è –∑–∞–±–∞–≤–Ω–æ–≥–æ/–Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–≥–æ, üßê –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ, üìä –¥–ª—è –¥–∞–Ω–Ω—ã—Ö/—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏, üí∞ –¥–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ)
   - –ó–∞—Ç–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
   - –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –≤ 2-3 –∫–æ—Ä–æ—Ç–∫–∏—Ö –∞–±–∑–∞—Ü–∞—Ö –ò–õ–ò –±—É–ª–ª–∏—Ç—ã (‚ñ∂Ô∏è) –µ—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞—è–≤–ª–µ–Ω–∏–π
   - –ï—Å–ª–∏ –Ω–æ–≤–æ—Å—Ç—å –≤—ã–∑—ã–≤–∞–µ—Ç –¥–∏—Å–∫—É—Å—Å–∏—é/–º–Ω–µ–Ω–∏–µ, –¥–æ–±–∞–≤—å –≤ –∫–æ–Ω—Ü–µ –∫–æ—Ä–æ—Ç–∫–∏–π –≤–æ–ø—Ä–æ—Å –∏ 2-3 –≤–∞—Ä–∏–∞–Ω—Ç–∞ —Ä–µ–∞–∫—Ü–∏–π-—ç–º–æ–¥–∑–∏
   - –î–ª—è —Å—É—Ö–∏—Ö —Ñ–∞–∫—Ç–æ–≤ –∏–ª–∏ –¥–ª–∏–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤ –ø—Ä–æ–ø—É—Å—Ç–∏ –æ–ø—Ä–æ—Å
   - –î–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ, –≤–æ–≤–ª–µ–∫–∞—é—â–µ –∏ –≥–æ—Ç–æ–≤–æ –∫ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—é
   
–ü—Ä–∏–º–µ—Ä —Ñ–æ—Ä–º–∞—Ç–∞ telegram_post:
"‚ö°Ô∏è–ú–∏–Ω–∏–º–∞–ª—å–Ω—É—é –ø–µ–Ω—Å–∏—é –≤ –†–æ—Å—Å–∏–∏ —Ö–æ—Ç—è—Ç —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ ‚ÇΩ35 —Ç—ã—Å—è—á\\n\\n–° —Ç–∞–∫–æ–π –∏–¥–µ–µ–π –≤—ã—Å—Ç—É–ø–∏–ª –¥–µ–ø—É—Ç–∞—Ç –ú–æ—Å–æ–±–ª–¥—É–º—ã –ê–Ω–∞—Ç–æ–ª–∏–π –ù–∏–∫–∏—Ç–∏–Ω. –ü–æ –µ–≥–æ —Å–ª–æ–≤–∞–º, —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–µ–Ω—Å–∏–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ —Å–∫–∞–∂–µ—Ç—Å—è –Ω–∞ –¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏. –ü–µ–Ω—Å–∏–æ–Ω–µ—Ä–∞–º –Ω–µ –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å, –æ–Ω–∏ —Å–º–æ–≥—É—Ç ¬´–±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ —É–¥–µ–ª—è—Ç—å –≤–Ω—É–∫–∞–º, –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –∏ –ø—Ä–∏–≤–∏–≤–∞—Ç—å —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ —Ü–µ–Ω–Ω–æ—Å—Ç–∏¬ª.\\n\\n–¢–∞–∫–∂–µ –¥–µ–ø—É—Ç–∞—Ç –æ—Ç–º–µ—Ç–∏–ª, —á—Ç–æ —Ç–∞–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ —É–≤–µ–ª–∏—á–∏—Ç —É—Ä–æ–≤–µ–Ω—å –∂–∏–∑–Ω–∏ –ø–æ–∂–∏–ª—ã—Ö –ª—é–¥–µ–π.\\n\\n–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º?\\n‚ù§Ô∏è‚Äçüî• ‚Äì –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ –¥–∞!\\nüòÅ ‚Äì –Ω–µ—Ç, –≤ —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –ª–∏–±–æ –ø–µ–Ω—Å–∏–æ–Ω–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç –ø–æ–≤—ã—Å—è—Ç, –ª–∏–±–æ —Ü–µ–Ω—ã –Ω–∞ —á—Ç–æ-–Ω–∏–±—É–¥—å –≤—ã—Ä–∞—Å—Ç—É—Ç\\nüê≥ ‚Äì –º–Ω–µ –±–µ–∑ —Ä–∞–∑–Ω–∏—Ü—ã"

–í–ê–ñ–ù–û: –í–°–ï –ø–æ–ª—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ù–ê –†–£–°–°–ö–û–ú –Ø–ó–´–ö–ï. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º."""

            result = llm.generate_json(prompt, temperature=0.5, max_tokens=2000)
            
            # Extract sources
            sources = [
                {
                    "url": art.get("url", ""),
                    "title": art.get("title", ""),
                    "published_at": str(art.get("published_at", "")),
                }
                for art in articles[:5]  # Top 5 sources
            ]
            
            # Convert draft to string if it's a dict
            draft_content = result.get("draft", "")
            if isinstance(draft_content, dict):
                # If LLM returned structured draft, convert to string
                lead = draft_content.get("lead", "")
                bullets = draft_content.get("bullets", [])
                quote = draft_content.get("quote", "")
                
                draft_str = f"{lead}\n\n"
                for bullet in bullets:
                    draft_str += f"- {bullet}\n"
                if quote:
                    draft_str += f"\n\"{quote}\""
                draft_content = draft_str
            
            # Get telegram_post
            telegram_post = result.get("telegram_post", "")
            if not telegram_post:
                # Fallback: create basic telegram post from headline
                telegram_post = f"‚ö°Ô∏è{result.get('headline', '–ù–æ–≤–æ—Å—Ç—å')}\n\n{result.get('why_now', '')}"
            
            final_results.append({
                "dedup_group": cluster["dedup_group"],
                "hotness": cluster["hotness"],
                "ml_hotness": cluster.get("ml_hotness", 0.0),
                "combined_hotness": cluster.get("combined_hotness", cluster["hotness"]),
                "headline": result.get("headline", "No headline"),
                "why_now": result.get("why_now", ""),
                "entities": result.get("entities", []),
                "sources": sources,
                "timeline": result.get("timeline", []),
                "draft": draft_content,
                "telegram_post": telegram_post,
            })
            
            log.info(f"Enriched cluster {cluster['dedup_group']} with LLM")
            
        except Exception as e:
            log.error(f"Failed to enrich cluster {cluster['dedup_group']}: {e}")
            # Fallback to basic data
            headline = articles[0].get("title", "")[:100]
            final_results.append({
                "dedup_group": cluster["dedup_group"],
                "hotness": cluster["hotness"],
                "ml_hotness": cluster.get("ml_hotness", 0.0),
                "combined_hotness": cluster.get("combined_hotness", cluster["hotness"]),
                "headline": headline,
                "why_now": "Analysis unavailable",
                "entities": [],
                "sources": [{"url": art.get("url", ""), "title": art.get("title", "")} for art in articles[:3]],
                "timeline": [],
                "draft": "",
                "telegram_post": f"üì∞{headline}\n\n–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ —Å–∫–æ—Ä–æ...",
            })
    
    state["final_output"] = final_results
    log.info(f"Enriched {len(final_results)} clusters")
    
    return state

