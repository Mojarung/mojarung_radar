"""Node functions for LangGraph agent pipeline"""
import asyncio
from typing import TypedDict, List, Dict, Any, Annotated
import uuid
from datetime import datetime
from collections import defaultdict
import polars as pl
from src.db.clickhouse_client import get_clickhouse_client
from src.db.session import get_db_context
from src.db.models import Source
from src.services.hotness_scorer import get_hotness_scorer
from src.services.ml_scorer import get_ml_scorer
from src.services.llm_client import get_llm_client
from src.core.logging_config import log


class AgentState(TypedDict):
    """State object passed between nodes in the graph"""
    time_window_hours: int
    top_k: int
    raw_articles: List[Dict[str, Any]]
    clustered_articles: Dict[str, List[Dict[str, Any]]]
    scored_clusters: List[Dict[str, Any]]
    enriched_results: List[Dict[str, Any]]
    final_output: List[Dict[str, Any]]


def fetch_recent_news_node(state: AgentState) -> AgentState:
    """Node 1: Fetch recent news from ClickHouse"""
    log.info(f"Fetching news from last {state['time_window_hours']} hours")
    
    clickhouse = get_clickhouse_client()
    articles = clickhouse.get_recent_articles(state["time_window_hours"])
    
    state["raw_articles"] = articles
    log.info(f"Fetched {len(articles)} articles")
    
    return state


def cluster_articles_node(state: AgentState) -> AgentState:
    """Node 2: Group articles by dedup_group"""
    log.info("Clustering articles by dedup_group")
    
    clusters = defaultdict(list)
    for article in state["raw_articles"]:
        dedup_group = article.get("dedup_group")
        if dedup_group:
            clusters[str(dedup_group)].append(article)
    
    state["clustered_articles"] = dict(clusters)
    log.info(f"Created {len(clusters)} clusters")
    
    return state


def calculate_hotness_node(state: AgentState) -> AgentState:
    """Node 3: Calculate hotness score for each cluster"""
    log.info("Calculating hotness scores")

    scorer = get_hotness_scorer()
    scored_clusters = []

    # Fetch source reputation scores
    with get_db_context() as db:
        sources = {s.id: s.reputation_score for s in db.query(Source).all()}

    for dedup_group, articles in state["clustered_articles"].items():
        # Get reputation scores for articles in this cluster
        reputation_scores = [
            sources.get(article.get("source_id"), 0.5)
            for article in articles
        ]

        hotness = scorer.calculate_hotness(
            articles=articles,
            source_reputation_scores=reputation_scores,
            time_window_hours=state["time_window_hours"],
        )

        scored_clusters.append({
            "dedup_group": dedup_group,
            "articles": articles,
            "hotness": hotness,
            "article_count": len(articles),
        })

    # Sort by hotness score (descending)
    scored_clusters.sort(key=lambda x: x["hotness"], reverse=True)

    state["scored_clusters"] = scored_clusters
    log.info(f"Scored {len(scored_clusters)} clusters")

    return state


def calculate_ml_hotness_node(state: AgentState) -> AgentState:
    """Node 3.5: Calculate ML-based hotness scores for clusters"""
    log.info("Calculating ML-based hotness scores")

    ml_scorer = get_ml_scorer()
    ml_scored_clusters = []

    for cluster in state["scored_clusters"]:
        dedup_group = cluster["dedup_group"]
        articles = cluster["articles"]

        # Get ML scores for all articles in this cluster
        ml_scored_articles = ml_scorer.score_articles(articles)

        # Calculate average ML score for the cluster
        ml_scores = [article.get("ml_hot_score", 0.0) for article in ml_scored_articles]
        avg_ml_score = sum(ml_scores) / len(ml_scores) if ml_scores else 0.0

        # Update cluster with ML score
        cluster_copy = cluster.copy()
        cluster_copy["ml_hotness"] = avg_ml_score
        cluster_copy["ml_scored_articles"] = ml_scored_articles

        ml_scored_clusters.append(cluster_copy)

    state["ml_scored_clusters"] = ml_scored_clusters
    log.info(f"Calculated ML scores for {len(ml_scored_clusters)} clusters")

    return state


def rank_and_select_node(state: AgentState) -> AgentState:
    """Node 4: Select top K clusters using combined scoring"""
    log.info(f"Selecting top {state['top_k']} clusters using combined scoring")

    # Get clusters with both traditional and ML scores
    clusters = state.get("ml_scored_clusters", state.get("scored_clusters", []))

    if not clusters:
        log.warning("No clusters available for ranking")
        state["enriched_results"] = []
        return state

    # Calculate combined scores for ranking
    for cluster in clusters:
        traditional_score = cluster.get("hotness", 0.0)
        ml_score = cluster.get("ml_hotness", 0.0)

        # Weighted combination (70% traditional, 30% ML for conservative approach)
        combined_score = (traditional_score * 0.7) + (ml_score * 0.3)
        cluster["combined_hotness"] = combined_score

        log.debug(f"Cluster {cluster['dedup_group'][:8]}: "
                 f"Traditional={traditional_score:.3f}, ML={ml_score:.3f}, "
                 f"Combined={combined_score:.3f}")

    # Sort by combined score (descending)
    clusters.sort(key=lambda x: x.get("combined_hotness", 0.0), reverse=True)

    # Select top K clusters
    top_clusters = clusters[: state["top_k"]]
    state["enriched_results"] = top_clusters

    log.info(f"Selected {len(top_clusters)} clusters for enrichment")
    log.info(f"Top cluster combined scores: {[(c['dedup_group'][:8], c.get('combined_hotness', 0.0)) for c in top_clusters]}")

    return state


async def enrich_with_llm_node_async(state: AgentState) -> AgentState:
    """Node 5: Enrich top clusters with LLM-generated content (async version)"""
    log.info("Enriching clusters with LLM (async)")

    llm = get_llm_client()
    final_results = []

    # Process clusters in parallel using asyncio
    async def process_cluster(cluster):
        articles = cluster["articles"]

        # Consolidate article content
        consolidated_text = "\n\n---\n\n".join([
            f"Title: {art.get('title', '')}\n"
            f"Source ID: {art.get('source_id', '')}\n"
            f"Published: {art.get('published_at', '')}\n"
            f"URL: {art.get('url', '')}\n"
            f"Content: {art.get('content', '')[:1000]}"  # Limit content length
            for art in articles
        ])

        # Generate enriched data with LLM
        try:
            prompt = f"""Ð¢Ñ‹ â€” Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ð¹ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð½Ð¾Ð¹ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº Ð¸ ÑÐ¾Ð·Ð´Ð°Ñ‚ÐµÐ»ÑŒ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð° Ð´Ð»Ñ Telegram. ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð½Ñ‹Ðµ ÑÑ‚Ð°Ñ‚ÑŒÐ¸ Ð¸ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²ÑŒ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚.

ÐÐ¾Ð²Ð¾ÑÑ‚Ð½Ñ‹Ðµ ÑÑ‚Ð°Ñ‚ÑŒÐ¸:
{consolidated_text}

Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐ¹ JSON Ð¾Ñ‚Ð²ÐµÑ‚ ÑÐ¾ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¼Ð¸ Ð¿Ð¾Ð»ÑÐ¼Ð¸:

1. "headline": ÐšÑ€Ð°Ñ‚ÐºÐ¸Ð¹, ÑÑ€ÐºÐ¸Ð¹ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº (Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 100 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²)

2. "why_now": 1-2 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ, Ð¾Ð±ÑŠÑÑÐ½ÑÑŽÑ‰Ð¸Ðµ, Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ ÑÑ‚Ð¾ Ð²Ð°Ð¶Ð½Ð¾ Ð¡Ð•Ð™Ð§ÐÐ¡ (Ð½Ð¾Ð²Ð¸Ð·Ð½Ð°, Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ, Ð¼Ð°ÑÑˆÑ‚Ð°Ð± Ð²Ð»Ð¸ÑÐ½Ð¸Ñ)

3. "entities": Ð¡Ð¿Ð¸ÑÐ¾Ðº ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹, Ñ‚Ð¸ÐºÐµÑ€Ð¾Ð², ÑÑ‚Ñ€Ð°Ð½ Ð¸Ð»Ð¸ ÑÐµÐºÑ‚Ð¾Ñ€Ð¾Ð², ÑƒÐ¿Ð¾Ð¼ÑÐ½ÑƒÑ‚Ñ‹Ñ… Ð² Ð½Ð¾Ð²Ð¾ÑÑ‚ÑÑ… (Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 10 ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¾Ð²)

4. "timeline": Ð¡Ð¿Ð¸ÑÐ¾Ðº ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ñ… Ñ‚Ð¾Ñ‡ÐµÐº Ñ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¼Ð¸ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸ÑÐ¼Ð¸ (Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚: [{{"time": "YYYY-MM-DD HH:MM", "event": "Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ"}}])

5. "draft": ÐŸÐ¾Ð»Ð½Ñ‹Ð¹ Ñ‡ÐµÑ€Ð½Ð¾Ð²Ð¸Ðº Ð¿Ð¾ÑÑ‚Ð° ÐºÐ°Ðº ÐžÐ”ÐÐ Ð¡Ð¢Ð ÐžÐšÐ Ñ markdown Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼. Ð’ÐºÐ»ÑŽÑ‡Ð¸:
   - Ð’Ð²Ð¾Ð´Ð½Ñ‹Ð¹ Ð¿Ð°Ñ€Ð°Ð³Ñ€Ð°Ñ„ (2-3 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ)
   - 3 ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… Ð¿ÑƒÐ½ÐºÑ‚Ð° (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ - Ð´Ð»Ñ Ð±ÑƒÐ»Ð»Ð¸Ñ‚Ð¾Ð²)
   - Ð ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½ÑƒÑŽ Ñ†Ð¸Ñ‚Ð°Ñ‚Ñƒ Ð¸Ð»Ð¸ ÑÑÑ‹Ð»ÐºÑƒ Ñ Ð°Ñ‚Ñ€Ð¸Ð±ÑƒÑ†Ð¸ÐµÐ¹

6. "telegram_post": Ð“Ð¾Ñ‚Ð¾Ð²Ñ‹Ð¹ Ðº Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ð¿Ð¾ÑÑ‚ Ð´Ð»Ñ Telegram Ð² ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐ¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ:
   - ÐÐ°Ñ‡Ð½Ð¸ Ñ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰ÐµÐ³Ð¾ ÑÐ¼Ð¾Ð´Ð·Ð¸ (âš¡ï¸ Ð´Ð»Ñ ÑÑ€Ð¾Ñ‡Ð½Ð¾Ð³Ð¾/Ð²Ð°Ð¶Ð½Ð¾Ð³Ð¾, ðŸ˜€ Ð´Ð»Ñ Ð·Ð°Ð±Ð°Ð²Ð½Ð¾Ð³Ð¾/Ð½ÐµÐ¾Ð¶Ð¸Ð´Ð°Ð½Ð½Ð¾Ð³Ð¾, ðŸ§ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾, ðŸ“Š Ð´Ð»Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…/ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸, ðŸ’° Ð´Ð»Ñ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ð¾Ð³Ð¾)
   - Ð—Ð°Ñ‚ÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº
   - ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð² 2-3 ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ñ… Ð°Ð±Ð·Ð°Ñ†Ð°Ñ… Ð˜Ð›Ð˜ Ð±ÑƒÐ»Ð»Ð¸Ñ‚Ñ‹ (â–¶ï¸) ÐµÑÐ»Ð¸ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð·Ð°ÑÐ²Ð»ÐµÐ½Ð¸Ð¹
   - Ð•ÑÐ»Ð¸ Ð½Ð¾Ð²Ð¾ÑÑ‚ÑŒ Ð²Ñ‹Ð·Ñ‹Ð²Ð°ÐµÑ‚ Ð´Ð¸ÑÐºÑƒÑÑÐ¸ÑŽ/Ð¼Ð½ÐµÐ½Ð¸Ðµ, Ð´Ð¾Ð±Ð°Ð²ÑŒ Ð² ÐºÐ¾Ð½Ñ†Ðµ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¸ 2-3 Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð° Ñ€ÐµÐ°ÐºÑ†Ð¸Ð¹-ÑÐ¼Ð¾Ð´Ð·Ð¸
   - Ð”Ð»Ñ ÑÑƒÑ…Ð¸Ñ… Ñ„Ð°ÐºÑ‚Ð¾Ð² Ð¸Ð»Ð¸ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ñ… ÑÐ¿Ð¸ÑÐºÐ¾Ð² Ð¿Ñ€Ð¾Ð¿ÑƒÑÑ‚Ð¸ Ð¾Ð¿Ñ€Ð¾Ñ
   - Ð”ÐµÐ»Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¾, Ð²Ð¾Ð²Ð»ÐµÐºÐ°ÑŽÑ‰Ðµ Ð¸ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾ Ðº ÐºÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÑŽ

ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð° telegram_post:
"âš¡ï¸ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð¿ÐµÐ½ÑÐ¸ÑŽ Ð² Ð Ð¾ÑÑÐ¸Ð¸ Ñ…Ð¾Ñ‚ÑÑ‚ ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ñ‚ÑŒ Ð´Ð¾ â‚½35 Ñ‚Ñ‹ÑÑÑ‡\\n\\nÐ¡ Ñ‚Ð°ÐºÐ¾Ð¹ Ð¸Ð´ÐµÐµÐ¹ Ð²Ñ‹ÑÑ‚ÑƒÐ¿Ð¸Ð» Ð´ÐµÐ¿ÑƒÑ‚Ð°Ñ‚ ÐœÐ¾ÑÐ¾Ð±Ð»Ð´ÑƒÐ¼Ñ‹ ÐÐ½Ð°Ñ‚Ð¾Ð»Ð¸Ð¹ ÐÐ¸ÐºÐ¸Ñ‚Ð¸Ð½. ÐŸÐ¾ ÐµÐ³Ð¾ ÑÐ»Ð¾Ð²Ð°Ð¼, ÑƒÐ²ÐµÐ»Ð¸Ñ‡ÐµÐ½Ð¸Ðµ Ð¿ÐµÐ½ÑÐ¸Ð¸ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ ÑÐºÐ°Ð¶ÐµÑ‚ÑÑ Ð½Ð° Ð´ÐµÐ¼Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ð¸Ð¸. ÐŸÐµÐ½ÑÐ¸Ð¾Ð½ÐµÑ€Ð°Ð¼ Ð½Ðµ Ð½ÑƒÐ¶Ð½Ð¾ Ð±ÑƒÐ´ÐµÑ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ, Ð¾Ð½Ð¸ ÑÐ¼Ð¾Ð³ÑƒÑ‚ Â«Ð±Ð¾Ð»ÑŒÑˆÐµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ ÑƒÐ´ÐµÐ»ÑÑ‚ÑŒ Ð²Ð½ÑƒÐºÐ°Ð¼, Ð¿ÐµÑ€ÐµÐ´Ð°Ð²Ð°Ñ‚ÑŒ Ð¸ Ð¿Ñ€Ð¸Ð²Ð¸Ð²Ð°Ñ‚ÑŒ Ñ‚Ñ€Ð°Ð´Ð¸Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ðµ Ñ†ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸Â».\\n\\nÐ¢Ð°ÐºÐ¶Ðµ Ð´ÐµÐ¿ÑƒÑ‚Ð°Ñ‚ Ð¾Ñ‚Ð¼ÐµÑ‚Ð¸Ð», Ñ‡Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ñ‚ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ Ð¶Ð¸Ð·Ð½Ð¸ Ð¿Ð¾Ð¶Ð¸Ð»Ñ‹Ñ… Ð»ÑŽÐ´ÐµÐ¹.\\n\\nÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÐ¼?\\nâ¤ï¸â€ðŸ”¥ â€“ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð½Ð¾ Ð´Ð°!\\nðŸ˜ â€“ Ð½ÐµÑ‚, Ð² Ñ‚Ð°ÐºÐ¾Ð¼ ÑÐ»ÑƒÑ‡Ð°Ðµ Ð»Ð¸Ð±Ð¾ Ð¿ÐµÐ½ÑÐ¸Ð¾Ð½Ð½Ñ‹Ð¹ Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚ Ð¿Ð¾Ð²Ñ‹ÑÑÑ‚, Ð»Ð¸Ð±Ð¾ Ñ†ÐµÐ½Ñ‹ Ð½Ð° Ñ‡Ñ‚Ð¾-Ð½Ð¸Ð±ÑƒÐ´ÑŒ Ð²Ñ‹Ñ€Ð°ÑÑ‚ÑƒÑ‚\\nðŸ³ â€“ Ð¼Ð½Ðµ Ð±ÐµÐ· Ñ€Ð°Ð·Ð½Ð¸Ñ†Ñ‹"

Ð’ÐÐ–ÐÐž: Ð’Ð¡Ð• Ð¿Ð¾Ð»Ñ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð±Ñ‹Ñ‚ÑŒ ÐÐ Ð Ð£Ð¡Ð¡ÐšÐžÐœ Ð¯Ð—Ð«ÐšÐ•. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼."""

            result = await llm.agenerate_json(prompt, temperature=0.5, max_tokens=2000)

            # Extract sources
            sources = [
                {
                    "url": art.get("url", ""),
                    "title": art.get("title", ""),
                    "published_at": str(art.get("published_at", "")),
                }
                for art in articles[:5]  # Top 5 sources
            ]

            # Convert draft to string if it's a dict
            draft_content = result.get("draft", "")
            if isinstance(draft_content, dict):
                # If LLM returned structured draft, convert to string
                lead = draft_content.get("lead", "")
                bullets = draft_content.get("bullets", [])
                quote = draft_content.get("quote", "")

                draft_str = f"{lead}\n\n"
                for bullet in bullets:
                    draft_str += f"- {bullet}\n"
                if quote:
                    draft_str += f"\n\"{quote}\""
                draft_content = draft_str

            # Get telegram_post
            telegram_post = result.get("telegram_post", "")
            if not telegram_post:
                # Fallback: create basic telegram post from headline
                telegram_post = f"âš¡ï¸{result.get('headline', 'ÐÐ¾Ð²Ð¾ÑÑ‚ÑŒ')}\n\n{result.get('why_now', '')}"

            return {
                "dedup_group": cluster["dedup_group"],
                "hotness": cluster["hotness"],
                "ml_hotness": cluster.get("ml_hotness", 0.0),
                "combined_hotness": cluster.get("combined_hotness", cluster["hotness"]),
                "headline": result.get("headline", "No headline"),
                "why_now": result.get("why_now", ""),
                "entities": result.get("entities", []),
                "sources": sources,
                "timeline": result.get("timeline", []),
                "draft": draft_content,
                "telegram_post": telegram_post,
            }

        except Exception as e:
            log.error(f"Failed to enrich cluster {cluster['dedup_group']}: {e}")
            # Fallback to basic data
            headline = articles[0].get("title", "")[:100]
            return {
                "dedup_group": cluster["dedup_group"],
                "hotness": cluster["hotness"],
                "ml_hotness": cluster.get("ml_hotness", 0.0),
                "combined_hotness": cluster.get("combined_hotness", cluster["hotness"]),
                "headline": headline,
                "why_now": "Analysis unavailable",
                "entities": [],
                "sources": [{"url": art.get("url", ""), "title": art.get("title", "")} for art in articles[:3]],
                "timeline": [],
                "draft": "",
                "telegram_post": f"ðŸ“°{headline}\n\nÐŸÐ¾Ð´Ñ€Ð¾Ð±Ð½Ð¾ÑÑ‚Ð¸ ÑÐºÐ¾Ñ€Ð¾...",
            }

    # Process all clusters in parallel
    tasks = [process_cluster(cluster) for cluster in state["enriched_results"]]
    cluster_results = await asyncio.gather(*tasks, return_exceptions=True)

    # Note: In thread executor context, this runs in a separate event loop

    # Handle exceptions and collect results
    for i, result in enumerate(cluster_results):
        if isinstance(result, Exception):
            log.error(f"Failed to process cluster {i}: {result}")
            # Add fallback result
            cluster = state["enriched_results"][i]
            articles = cluster["articles"]
            headline = articles[0].get("title", "")[:100]
            final_results.append({
                "dedup_group": cluster["dedup_group"],
                "hotness": cluster["hotness"],
                "ml_hotness": cluster.get("ml_hotness", 0.0),
                "combined_hotness": cluster.get("combined_hotness", cluster["hotness"]),
                "headline": headline,
                "why_now": "Analysis unavailable",
                "entities": [],
                "sources": [{"url": art.get("url", ""), "title": art.get("title", "")} for art in articles[:3]],
                "timeline": [],
                "draft": "",
                "telegram_post": f"ðŸ“°{headline}\n\nÐŸÐ¾Ð´Ñ€Ð¾Ð±Ð½Ð¾ÑÑ‚Ð¸ ÑÐºÐ¾Ñ€Ð¾...",
            })
        else:
            final_results.append(result)
            log.info(f"Enriched cluster {result['dedup_group']} with LLM")

    state["final_output"] = final_results
    log.info(f"Enriched {len(final_results)} clusters (async)")

    return state


def enrich_with_llm_node(state: AgentState) -> AgentState:
    """Node 5: Enrich top clusters with LLM-generated content (sync wrapper)"""
    # Use thread executor for async processing to avoid event loop conflicts
    import concurrent.futures

    def run_async_enrichment():
        loop = None
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            return loop.run_until_complete(enrich_with_llm_node_async(state))
        finally:
            if loop:
                loop.close()

    with concurrent.futures.ThreadPoolExecutor() as executor:
        future = executor.submit(run_async_enrichment)
        return future.result()

